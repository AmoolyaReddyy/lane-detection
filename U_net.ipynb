{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AmoolyaReddyy/lane-detection/blob/main/U_net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbDsobsTX2Vf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02f2ab49-b009-44fd-e06f-aef4567e9788"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random\n",
        "import cv2\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0jGQf7jxVqw",
        "outputId": "83be6387-9984-4967-c64f-78ef8b0559d5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwyJP9B5-ZUP"
      },
      "source": [
        "from tensorflow.keras.models import Model,load_model\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.layers import Conv2D, ZeroPadding2D, Input, BatchNormalization, Activation, Add\n",
        "from tensorflow.keras.layers import AveragePooling2D, Flatten, Conv2DTranspose, concatenate, MaxPool2D, SeparableConv2D,Cropping2D,UpSampling2D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_SAPSrPusuL"
      },
      "source": [
        "def _parse_image_function(example_proto):\n",
        "    \"\"\"Mapping function for parsing images and annotations from the tfrecord files. Transforms and augments images and annotations before training.\n",
        "        Args:\n",
        "            example_proto: a single element from the dataset\n",
        "        Returns:\n",
        "            image: transformed image extracted from the datatset\n",
        "            annotation: transformed annotation extracted from the datatset\n",
        "    \"\"\"\n",
        "\n",
        "    #This descibes the structure of each element in the dataset\n",
        "    image_feature_description={\n",
        "        'height':tf.io.FixedLenFeature([], tf.int64),\n",
        "        'width': tf.io.FixedLenFeature([], tf.int64),\n",
        "        'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
        "        'mask_raw': tf.io.FixedLenFeature([], tf.string)\n",
        "        }\n",
        "\n",
        "    #The features are extracted to a dictionary\n",
        "    feature=tf.io.parse_single_example(example_proto, image_feature_description)\n",
        "    #Images and Annotations are resized to (192,192)\n",
        "    image = tf.image.decode_jpeg(feature['image_raw'])\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    annotation = tf.image.decode_png(feature['mask_raw'], channels=1)\n",
        "    annotation = tf.cast(annotation, tf.float32) / 1.0\n",
        "\n",
        "    image = tf.reshape(image, (360,640,3))\n",
        "    annotation = tf.reshape(annotation, (360,640,1))\n",
        "\n",
        "    image = tf.image.pad_to_bounding_box(image, 140, 0, 640, 640)\n",
        "    annotation = tf.image.pad_to_bounding_box(annotation, 140, 0, 640, 640)\n",
        "\n",
        "    image = tf.image.resize(image, size=(192,192))\n",
        "    annotation = tf.image.resize(annotation, size=(192,192))\n",
        "\n",
        "    #Randomly flips images and annotations\n",
        "    if(random.random() > 0.5):\n",
        "        image = tf.image.flip_left_right(image)\n",
        "        annotation = tf.image.flip_left_right(annotation)\n",
        "\n",
        "\n",
        "    return image, annotation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLlf-i2Xu3Zj"
      },
      "source": [
        "BATCH_SIZE = 8\n",
        "\n",
        "train_dataset = tf.data.TFRecordDataset(['/content/drive/My Drive/RUGVED/Lane-Extraction-from-Grass-Surfaces-master/Dataset/tfrecords/train.tfrecords'])\n",
        "train_dataset = train_dataset.map(_parse_image_function)\n",
        "ds_train = train_dataset.shuffle(buffer_size=584)\n",
        "ds_train = ds_train.repeat()\n",
        "ds_train = ds_train.batch(BATCH_SIZE)\n",
        "ds_train = ds_train.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "val_dataset = tf.data.TFRecordDataset('/content/drive/My Drive/RUGVED/Lane-Extraction-from-Grass-Surfaces-master/Dataset/tfrecords/val.tfrecords')\n",
        "val_dataset = val_dataset.map(_parse_image_function)\n",
        "ds_val = val_dataset.shuffle(buffer_size=32)\n",
        "ds_val = ds_val.repeat()\n",
        "ds_val = ds_val.batch(BATCH_SIZE)\n",
        "ds_val = ds_val.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "test_dataset = tf.data.TFRecordDataset('/content/drive/My Drive/RUGVED/Lane-Extraction-from-Grass-Surfaces-master/Dataset/tfrecords/test.tfrecords')\n",
        "test_dataset = test_dataset.map(_parse_image_function)\n",
        "ds_test = test_dataset.shuffle(buffer_size=34)\n",
        "ds_test = ds_test.repeat()\n",
        "ds_test = ds_test.batch(BATCH_SIZE)\n",
        "ds_test = ds_test.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "In_P8fW1k4x2"
      },
      "source": [
        "def u_net():\n",
        "  #Encoder\n",
        "  input_image = Input(shape=(192,192,3), name='input')\n",
        "  c1=Conv2D(64,3,activation='relu',padding='same',kernel_initializer='he_normal')(input_image)\n",
        "  c1=Conv2D(64,3,activation='relu',padding='same',kernel_initializer='he_normal')(c1)\n",
        "  p1=MaxPool2D(pool_size=(2,2),strides=2)(c1)\n",
        "\n",
        "  c2=Conv2D(128,3,activation='relu',padding='same',kernel_initializer='he_normal')(p1)\n",
        "  c2=Conv2D(128,3,activation='relu',padding='same',kernel_initializer='he_normal')(c2)\n",
        "  p2=MaxPool2D(pool_size=(2,2),strides=2)(c2)\n",
        "\n",
        "  c3=Conv2D(256,3,activation='relu',padding='same',kernel_initializer='he_normal')(p2)\n",
        "  c3=Conv2D(256,3,activation='relu',padding='same',kernel_initializer='he_normal')(c3)\n",
        "  p3=MaxPool2D(pool_size=(2,2),strides=2)(c3)\n",
        "\n",
        "\n",
        "  c4=Conv2D(512,3,activation='relu',padding='same',kernel_initializer='he_normal')(p3)\n",
        "  c4=Conv2D(512,3,activation='relu',padding='same',kernel_initializer='he_normal')(c4)\n",
        "  p4=MaxPool2D(pool_size=(2,2),strides=2)(c4)\n",
        "\n",
        "  c5=Conv2D(1024,3,activation='relu',padding='same',kernel_initializer='he_normal')(p4)\n",
        "  c5=Conv2D(1024,3,activation='relu',padding='same',kernel_initializer='he_normal')(c5)\n",
        "  #Decoder\n",
        "  up5 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(c5))\n",
        "\n",
        "  s=int((c4.shape[1]-up5.shape[1])/2);\n",
        "  cc4=Cropping2D(cropping=((s, s), (s, s)), data_format=None)(c4)\n",
        "  m1 = concatenate([cc4,up5], axis = 3)\n",
        "\n",
        "\n",
        "  c6=Conv2D(512,3,activation='relu',padding='same',kernel_initializer='he_normal')(m1)\n",
        "  c6=Conv2D(512,3,activation='relu',padding='same',kernel_initializer='he_normal')(c6)\n",
        "  up6 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(c6))\n",
        "\n",
        "  s=int((c3.shape[1]-up6.shape[1])/2)\n",
        "  cc3=Cropping2D(cropping=((s, s), (s, s)), data_format=None)(c3)\n",
        "  m2 = concatenate([cc3,up6], axis = 3)\n",
        "\n",
        "\n",
        "  c7=Conv2D(256,3,activation='relu',padding='same',kernel_initializer='he_normal')(m2)\n",
        "  c7=Conv2D(256,3,activation='relu',padding='same',kernel_initializer='he_normal')(c7)\n",
        "  up7 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(c7))\n",
        "\n",
        "  s=int((c2.shape[1]-up7.shape[1])/2);\n",
        "  cc2=Cropping2D(cropping=((s, s), (s, s)), data_format=None)(c2)\n",
        "  m3 = concatenate([cc2,up7], axis = 3)\n",
        "\n",
        "  c8=Conv2D(128,3,activation='relu',padding='same',kernel_initializer='he_normal')(m3)\n",
        "  c8=Conv2D(128,3,activation='relu',padding='same',kernel_initializer='he_normal')(c8)\n",
        "  up8 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(c8))\n",
        "\n",
        "  s=int((c1.shape[1]-up8.shape[1])/2);\n",
        "  cc1=Cropping2D(cropping=((s, s), (s, s)), data_format=None)(c1)\n",
        "  m4 = concatenate([cc1,up8], axis = 3)\n",
        "\n",
        "  c9=Conv2D(64,3,activation='relu',padding='same',kernel_initializer='he_normal')(m4)\n",
        "  c9=Conv2D(64,3,activation='relu',padding='same',kernel_initializer='he_normal')(c9)\n",
        "  op = Conv2D(1, 1, activation = 'sigmoid', padding = 'same', kernel_initializer = 'he_normal')(c9)\n",
        "  model = Model(inputs=[input_image], outputs=[op])\n",
        "  return model\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2ttiusp4Br9"
      },
      "source": [
        "model=u_net()\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5pufc4vOshx"
      },
      "source": [
        "def step_decay(epoch):\n",
        "\n",
        "    initial_lrate = 0.001\n",
        "    drop = 0.9\n",
        "    epochs_drop = 2\n",
        "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
        "    return lrate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnbp_079vIVT"
      },
      "source": [
        "lrate = LearningRateScheduler(step_decay)\n",
        "class myCallBack(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if(logs.get('accuracy') >= 0.995):\n",
        "            self.model.stop_training = True\n",
        "\n",
        "callback = myCallBack()\n",
        "\n",
        "checkpoint_path = \"/content/drive/My Drive/RUGVED/training_1/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)\n",
        "callbacks_list = [lrate, callback,cp_callback]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vx7IcdvxvXYd"
      },
      "source": [
        "iterator = iter(ds_train)\n",
        "iterator1 = iter(ds_val)\n",
        "iterator2=iter(ds_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggqKyGP8vakd"
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.0), loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWk9blk4vfTC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "e4074981-66e5-420b-bfb5-82118872aab1"
      },
      "source": [
        "history = model.fit(iterator,steps_per_epoch=600//BATCH_SIZE,epochs=20, validation_data=iterator1, validation_steps=1, callbacks=callbacks_list, verbose = 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-19468cd948e0>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0miterator1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TMgGpuzw9RZ",
        "outputId": "1dbdbde3-bda5-465d-dfe9-a9cdbd719e8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-cbef26aec70f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGZIM_ODvijq"
      },
      "source": [
        "model.evaluate(iterator2,batch_size=16, steps=20,verbose = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BfLeMxki5bG"
      },
      "source": [
        "model.save('funet.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iNpD2c136vB"
      },
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from PIL import Image as im\n",
        "from tensorflow.keras.models import Model,load_model\n",
        "model = load_model('/content/drive/My Drive/RUGVED/funet.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRZ6DjheD-2x"
      },
      "source": [
        "img_path='/content/drive/My Drive/RUGVED/testing_images/image_5.webp'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBmEdAgwO5l-"
      },
      "source": [
        "!ls '/content/drive/My Drive/RUGVED'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GM17pqRGKKv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "d252ccbc-be14-4723-ae91-47c55a566bc7"
      },
      "source": [
        "\n",
        "\n",
        "def predict(img_path):\n",
        "    img = image.load_img(img_path, target_size=(192,192))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_batch = np.expand_dims(img_array, axis=0)\n",
        "    img_preprocessed = img_batch\n",
        "    mask = model.predict([[img_preprocessed]])\n",
        "    mask = np.resize(mask, (192,192))\n",
        "    #mask = np.round(mask)\n",
        "    mask = mask * 255\n",
        "\n",
        "    '''print(mask[(np.where(mask >= 0.5)) and (np.where(mask <1))].size)'''\n",
        "    fig = plt.figure(figsize=(10, 7))\n",
        "    rows = 1\n",
        "    columns = 2\n",
        "    fig.add_subplot(rows, columns, 1)\n",
        "    plt.imshow(img )\n",
        "    plt.title(\"Input_image\")\n",
        "    fig.add_subplot(rows, columns, 2)\n",
        "    plt.imshow(mask,cmap='Greys_r')\n",
        "    plt.title(\"Mask\")\n",
        "\n",
        "predict(img_path)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-d8aad0d6f52f>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mask\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'img_path' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXn3_6vzjyzL"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}